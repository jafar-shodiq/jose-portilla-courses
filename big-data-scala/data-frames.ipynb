{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Overview**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "import org.apache.spark.sql.SparkSession\r\n",
       "spark: org.apache.spark.sql.SparkSession = org.apache.spark.sql.SparkSession@2a7dc01c\r\n"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import org.apache.spark.sql.SparkSession\n",
    "\n",
    "val spark = SparkSession.builder().getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "df: org.apache.spark.sql.DataFrame = [_c0: string, _c1: string ... 4 more fields]\r\n"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val df = spark.read.csv(\"./datasets/CitiGroup2006_2008\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "res1: Array[org.apache.spark.sql.Row] = Array([Date,Open,High,Low,Close,Volume], [2006-01-03,490.0,493.8,481.1,492.9,1537660], [2006-01-04,488.6,491.0,483.5,483.8,1871020], [2006-01-05,484.4,487.8,484.0,486.2,1143160], [2006-01-06,488.8,489.0,482.0,486.2,1370250])\r\n"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Date,Open,High,Low,Close,Volume]\n",
      "[2006-01-03,490.0,493.8,481.1,492.9,1537660]\n",
      "[2006-01-04,488.6,491.0,483.5,483.8,1871020]\n",
      "[2006-01-05,484.4,487.8,484.0,486.2,1143160]\n",
      "[2006-01-06,488.8,489.0,482.0,486.2,1370250]\n"
     ]
    }
   ],
   "source": [
    "for(row <- df.head(5)){\n",
    "    println(row)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2006-01-03,490.0,493.8,481.1,492.9,1537660]\n",
      "[2006-01-04,488.6,491.0,483.5,483.8,1871020]\n",
      "[2006-01-05,484.4,487.8,484.0,486.2,1143160]\n",
      "[2006-01-06,488.8,489.0,482.0,486.2,1370250]\n",
      "[2006-01-09,486.0,487.4,483.0,483.9,1680740]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "df: org.apache.spark.sql.DataFrame = [Date: string, Open: double ... 4 more fields]\r\n"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val df = spark.read.option(\"header\", \"true\").option(\"inferSchema\", \"true\").csv(\"./datasets/CitiGroup2006_2008\")\n",
    "\n",
    "for(row <- df.head(5)){\n",
    "    println(row)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "res7: Array[String] = Array(Date, Open, High, Low, Close, Volume)\r\n"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+----------+------------------+-----------------+------------------+------------------+-----------------+\n",
      "|summary|      Date|              Open|             High|               Low|             Close|           Volume|\n",
      "+-------+----------+------------------+-----------------+------------------+------------------+-----------------+\n",
      "|  count|       755|               755|              755|               755|               755|              755|\n",
      "|   mean|      null| 386.0923178807949|390.6590596026489|380.80170860927143| 385.3421456953643|6308596.382781457|\n",
      "| stddev|      null|149.32301134820133|148.5151130063523|150.53136890891344|149.83310074439177| 8099892.56297633|\n",
      "|    min|2006-01-03|              54.4|             55.3|              30.5|              37.7|           632860|\n",
      "|    max|2008-12-31|             566.0|            570.0|             555.5|             564.1|        102869289|\n",
      "+-------+----------+------------------+-----------------+------------------+------------------+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.describe().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+\n",
      "| Volume|\n",
      "+-------+\n",
      "|1537660|\n",
      "|1871020|\n",
      "|1143160|\n",
      "|1370250|\n",
      "|1680740|\n",
      "|1365960|\n",
      "|1684440|\n",
      "|1230060|\n",
      "| 940930|\n",
      "|1237830|\n",
      "|1218910|\n",
      "|1696500|\n",
      "|4781930|\n",
      "|2025500|\n",
      "|2083740|\n",
      "|1591940|\n",
      "|1988600|\n",
      "|1412760|\n",
      "|1057630|\n",
      "|1887280|\n",
      "+-------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(\"Volume\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----+\n",
      "|      Date|Close|\n",
      "+----------+-----+\n",
      "|2006-01-03|492.9|\n",
      "|2006-01-04|483.8|\n",
      "|2006-01-05|486.2|\n",
      "|2006-01-06|486.2|\n",
      "|2006-01-09|483.9|\n",
      "|2006-01-10|485.4|\n",
      "|2006-01-11|489.8|\n",
      "|2006-01-12|490.3|\n",
      "|2006-01-13|489.2|\n",
      "|2006-01-17|484.3|\n",
      "|2006-01-18|483.8|\n",
      "|2006-01-19|479.4|\n",
      "|2006-01-20|456.9|\n",
      "|2006-01-23|460.0|\n",
      "|2006-01-24|460.1|\n",
      "|2006-01-25|462.3|\n",
      "|2006-01-26|470.1|\n",
      "|2006-01-27|468.7|\n",
      "|2006-01-30|468.2|\n",
      "|2006-01-31|465.8|\n",
      "+----------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(\"Date\", \"Close\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----+-----+-----+-----+-------+-----------------+\n",
      "|      Date| Open| High|  Low|Close| Volume|      HighPlusLow|\n",
      "+----------+-----+-----+-----+-----+-------+-----------------+\n",
      "|2006-01-03|490.0|493.8|481.1|492.9|1537660|974.9000000000001|\n",
      "|2006-01-04|488.6|491.0|483.5|483.8|1871020|            974.5|\n",
      "|2006-01-05|484.4|487.8|484.0|486.2|1143160|            971.8|\n",
      "|2006-01-06|488.8|489.0|482.0|486.2|1370250|            971.0|\n",
      "|2006-01-09|486.0|487.4|483.0|483.9|1680740|            970.4|\n",
      "|2006-01-10|483.0|485.5|480.8|485.4|1365960|            966.3|\n",
      "|2006-01-11|495.8|495.8|485.8|489.8|1684440|            981.6|\n",
      "|2006-01-12|491.0|491.0|488.8|490.3|1230060|            979.8|\n",
      "|2006-01-13|491.0|491.9|487.3|489.2| 940930|            979.2|\n",
      "|2006-01-17|485.1|487.0|482.7|484.3|1237830|            969.7|\n",
      "|2006-01-18|484.3|486.7|481.1|483.8|1218910|            967.8|\n",
      "|2006-01-19|485.6|485.8|477.0|479.4|1696500|            962.8|\n",
      "|2006-01-20|472.1|474.0|456.3|456.9|4781930|            930.3|\n",
      "|2006-01-23|460.0|463.8|457.0|460.0|2025500|            920.8|\n",
      "|2006-01-24|462.9|463.6|459.9|460.1|2083740|            923.5|\n",
      "|2006-01-25|461.4|463.7|460.1|462.3|1591940|            923.8|\n",
      "|2006-01-26|465.5|475.5|464.5|470.1|1988600|            940.0|\n",
      "|2006-01-27|470.1|473.7|466.0|468.7|1412760|            939.7|\n",
      "|2006-01-30|468.7|469.9|466.6|468.2|1057630|            936.5|\n",
      "|2006-01-31|468.3|470.5|465.5|465.8|1887280|            936.0|\n",
      "+----------+-----+-----+-----+-----+-------+-----------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "df2: org.apache.spark.sql.DataFrame = [Date: string, Open: double ... 5 more fields]\r\n"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val df2 = df.withColumn(\"HighPlusLow\", df(\"High\") + df(\"Low\"))\n",
    "df2.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Date: string (nullable = true)\n",
      " |-- Open: double (nullable = true)\n",
      " |-- High: double (nullable = true)\n",
      " |-- Low: double (nullable = true)\n",
      " |-- Close: double (nullable = true)\n",
      " |-- Volume: integer (nullable = true)\n",
      " |-- HighPlusLow: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df2.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+\n",
      "|              HPL|\n",
      "+-----------------+\n",
      "|974.9000000000001|\n",
      "|            974.5|\n",
      "|            971.8|\n",
      "|            971.0|\n",
      "|            970.4|\n",
      "|            966.3|\n",
      "|            981.6|\n",
      "|            979.8|\n",
      "|            979.2|\n",
      "|            969.7|\n",
      "|            967.8|\n",
      "|            962.8|\n",
      "|            930.3|\n",
      "|            920.8|\n",
      "|            923.5|\n",
      "|            923.8|\n",
      "|            940.0|\n",
      "|            939.7|\n",
      "|            936.5|\n",
      "|            936.0|\n",
      "+-----------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df2.select(df2(\"HighPlusLow\").as(\"HPL\")).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Operations**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "import org.apache.spark.sql.SparkSession\r\n",
       "spark: org.apache.spark.sql.SparkSession = org.apache.spark.sql.SparkSession@2a7dc01c\r\n"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import org.apache.spark.sql.SparkSession\n",
    "\n",
    "val spark = SparkSession.builder().getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Date: string (nullable = true)\n",
      " |-- Open: double (nullable = true)\n",
      " |-- High: double (nullable = true)\n",
      " |-- Low: double (nullable = true)\n",
      " |-- Close: double (nullable = true)\n",
      " |-- Volume: integer (nullable = true)\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "df: org.apache.spark.sql.DataFrame = [Date: string, Open: double ... 4 more fields]\r\n"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val df = spark.read.option(\"header\", \"true\").option(\"inferSchema\", \"true\").csv(\"./datasets/CitiGroup2006_2008\")\n",
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "import spark.implicits._\r\n"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import spark.implicits._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----+-----+-----+-----+-------+\n",
      "|      Date| Open| High|  Low|Close| Volume|\n",
      "+----------+-----+-----+-----+-----+-------+\n",
      "|2006-01-20|472.1|474.0|456.3|456.9|4781930|\n",
      "|2006-01-23|460.0|463.8|457.0|460.0|2025500|\n",
      "|2006-01-24|462.9|463.6|459.9|460.1|2083740|\n",
      "|2006-01-25|461.4|463.7|460.1|462.3|1591940|\n",
      "|2006-01-26|465.5|475.5|464.5|470.1|1988600|\n",
      "|2006-01-27|470.1|473.7|466.0|468.7|1412760|\n",
      "|2006-01-30|468.7|469.9|466.6|468.2|1057630|\n",
      "|2006-01-31|468.3|470.5|465.5|465.8|1887280|\n",
      "|2006-02-01|465.9|467.2|461.1|463.3|1844970|\n",
      "|2006-02-02|459.0|461.0|451.0|451.8|2325470|\n",
      "|2006-02-03|450.7|456.1|448.1|450.6|1666510|\n",
      "|2006-02-06|452.6|456.1|450.9|451.7|1147430|\n",
      "|2006-02-07|452.0|453.8|450.0|450.5|1207780|\n",
      "|2006-02-08|453.3|455.3|450.7|453.6|1051370|\n",
      "|2006-02-09|455.0|461.0|454.3|457.9|1357740|\n",
      "|2006-02-10|457.0|460.7|452.5|459.6|1272030|\n",
      "|2006-02-13|460.6|462.3|454.1|456.8|1158300|\n",
      "|2006-02-14|457.8|462.5|457.1|461.2|1518040|\n",
      "|2006-02-15|460.4|464.7|457.6|462.5|1700050|\n",
      "|2006-02-16|463.0|464.4|460.4|464.4|1326000|\n",
      "+----------+-----+-----+-----+-----+-------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.filter(($\"Close\" < 480) && ($\"High\" < 480)).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----+-----+-----+-----+-------+\n",
      "|      Date| Open| High|  Low|Close| Volume|\n",
      "+----------+-----+-----+-----+-----+-------+\n",
      "|2006-01-20|472.1|474.0|456.3|456.9|4781930|\n",
      "|2006-01-23|460.0|463.8|457.0|460.0|2025500|\n",
      "|2006-01-24|462.9|463.6|459.9|460.1|2083740|\n",
      "|2006-01-25|461.4|463.7|460.1|462.3|1591940|\n",
      "|2006-01-26|465.5|475.5|464.5|470.1|1988600|\n",
      "|2006-01-27|470.1|473.7|466.0|468.7|1412760|\n",
      "|2006-01-30|468.7|469.9|466.6|468.2|1057630|\n",
      "|2006-01-31|468.3|470.5|465.5|465.8|1887280|\n",
      "|2006-02-01|465.9|467.2|461.1|463.3|1844970|\n",
      "|2006-02-02|459.0|461.0|451.0|451.8|2325470|\n",
      "|2006-02-03|450.7|456.1|448.1|450.6|1666510|\n",
      "|2006-02-06|452.6|456.1|450.9|451.7|1147430|\n",
      "|2006-02-07|452.0|453.8|450.0|450.5|1207780|\n",
      "|2006-02-08|453.3|455.3|450.7|453.6|1051370|\n",
      "|2006-02-09|455.0|461.0|454.3|457.9|1357740|\n",
      "|2006-02-10|457.0|460.7|452.5|459.6|1272030|\n",
      "|2006-02-13|460.6|462.3|454.1|456.8|1158300|\n",
      "|2006-02-14|457.8|462.5|457.1|461.2|1518040|\n",
      "|2006-02-15|460.4|464.7|457.6|462.5|1700050|\n",
      "|2006-02-16|463.0|464.4|460.4|464.4|1326000|\n",
      "+----------+-----+-----+-----+-----+-------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.filter(\"Close < 480 AND High < 480\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----+-----+-----+-----+-------+\n",
      "|      Date| Open| High|  Low|Close| Volume|\n",
      "+----------+-----+-----+-----+-----+-------+\n",
      "|2006-01-20|472.1|474.0|456.3|456.9|4781930|\n",
      "+----------+-----+-----+-----+-----+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.filter($\"High\" === 474.0).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----+-----+-----+-----+-------+\n",
      "|      Date| Open| High|  Low|Close| Volume|\n",
      "+----------+-----+-----+-----+-----+-------+\n",
      "|2006-01-20|472.1|474.0|456.3|456.9|4781930|\n",
      "+----------+-----+-----+-----+-----+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.filter(\"High = 474.0\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "res37: Array[org.apache.spark.sql.Row] = Array([2006-01-03,490.0,493.8,481.1,492.9,1537660], [2006-01-04,488.6,491.0,483.5,483.8,1871020], [2006-01-05,484.4,487.8,484.0,486.2,1143160], [2006-01-06,488.8,489.0,482.0,486.2,1370250], [2006-01-09,486.0,487.4,483.0,483.9,1680740], [2006-01-10,483.0,485.5,480.8,485.4,1365960], [2006-01-11,495.8,495.8,485.8,489.8,1684440], [2006-01-12,491.0,491.0,488.8,490.3,1230060], [2006-01-13,491.0,491.9,487.3,489.2,940930], [2006-01-17,485.1,487.0,482.7,484.3,1237830], [2006-01-18,484.3,486.7,481.1,483.8,1218910], [2006-01-19,485.6,485.8,477.0,479.4,1696500], [2006-01-20,472.1,474.0,456.3,456.9,4781930], [2006-01-23,460.0,463.8,457.0,460.0,2025500], [2006-01-24,462.9,463.6,459.9,460.1,2083740], [2006-01-25,461.4,463.7,460.1,462.3,1591940], [2006-01-26,465...\r\n"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "res38: Long = 755\r\n"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+\n",
      "|   corr(High, Low)|\n",
      "+------------------+\n",
      "|0.9992999172726325|\n",
      "+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(corr(\"High\", \"Low\")).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Groupby and aggregrate functions**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "import org.apache.spark.sql.SparkSession\r\n",
       "spark: org.apache.spark.sql.SparkSession = org.apache.spark.sql.SparkSession@2a7dc01c\r\n"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import org.apache.spark.sql.SparkSession\n",
    "val spark = SparkSession.builder().getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Company: string (nullable = true)\n",
      " |-- Person: string (nullable = true)\n",
      " |-- Sales: integer (nullable = true)\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "df: org.apache.spark.sql.DataFrame = [Company: string, Person: string ... 1 more field]\r\n"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val df = spark.read.option(\"header\", \"true\").option(\"inferSchema\", \"true\").csv(\"./datasets/Sales.csv\")\n",
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------+-----+\n",
      "|Company| Person|Sales|\n",
      "+-------+-------+-----+\n",
      "|   GOOG|    Sam|  200|\n",
      "|   GOOG|Charlie|  120|\n",
      "|   GOOG|  Frank|  340|\n",
      "|   MSFT|   Tina|  600|\n",
      "|   MSFT|    Amy|  124|\n",
      "|   MSFT|Vanessa|  243|\n",
      "|     FB|   Carl|  870|\n",
      "|     FB|  Sarah|  350|\n",
      "+-------+-------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----------------+\n",
      "|Company|       avg(Sales)|\n",
      "+-------+-----------------+\n",
      "|   GOOG|            220.0|\n",
      "|     FB|            610.0|\n",
      "|   MSFT|322.3333333333333|\n",
      "+-------+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.groupBy($\"Company\").mean().show() // max, min, sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------------+\n",
      "|count(DISTINCT Sales)|\n",
      "+---------------------+\n",
      "|                    8|\n",
      "+---------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(countDistinct($\"Sales\")).show() // sumDistinct, variance, (stddev, max, min, avg, sum), collect_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------+-----+\n",
      "|Company| Person|Sales|\n",
      "+-------+-------+-----+\n",
      "|   GOOG|Charlie|  120|\n",
      "|   MSFT|    Amy|  124|\n",
      "|   GOOG|    Sam|  200|\n",
      "|   MSFT|Vanessa|  243|\n",
      "|   GOOG|  Frank|  340|\n",
      "|     FB|  Sarah|  350|\n",
      "|   MSFT|   Tina|  600|\n",
      "|     FB|   Carl|  870|\n",
      "+-------+-------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.orderBy($\"Sales\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------+-----+\n",
      "|Company| Person|Sales|\n",
      "+-------+-------+-----+\n",
      "|     FB|   Carl|  870|\n",
      "|   MSFT|   Tina|  600|\n",
      "|     FB|  Sarah|  350|\n",
      "|   GOOG|  Frank|  340|\n",
      "|   MSFT|Vanessa|  243|\n",
      "|   GOOG|    Sam|  200|\n",
      "|   MSFT|    Amy|  124|\n",
      "|   GOOG|Charlie|  120|\n",
      "+-------+-------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.orderBy($\"Sales\".desc).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Missing data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "import org.apache.spark.sql.SparkSession\r\n",
       "spark: org.apache.spark.sql.SparkSession = org.apache.spark.sql.SparkSession@2a7dc01c\r\n"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import org.apache.spark.sql.SparkSession\n",
    "val spark = SparkSession.builder().getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-----+-----+\n",
      "|  Id| Name|Sales|\n",
      "+----+-----+-----+\n",
      "|emp1| John| null|\n",
      "|emp2| null| null|\n",
      "|emp3| null|345.0|\n",
      "|emp4|Cindy|456.0|\n",
      "+----+-----+-----+\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "df: org.apache.spark.sql.DataFrame = [Id: string, Name: string ... 1 more field]\r\n"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val df = spark.read.option(\"header\", \"true\").option(\"inferSchema\", \"true\").csv(\"./datasets/ContainsNull.csv\")\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Id: string (nullable = true)\n",
      " |-- Name: string (nullable = true)\n",
      " |-- Sales: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-----+-----+\n",
      "|  Id| Name|Sales|\n",
      "+----+-----+-----+\n",
      "|emp4|Cindy|456.0|\n",
      "+----+-----+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.na.drop().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-----+-----+\n",
      "|  Id| Name|Sales|\n",
      "+----+-----+-----+\n",
      "|emp1| John| null|\n",
      "|emp3| null|345.0|\n",
      "|emp4|Cindy|456.0|\n",
      "+----+-----+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.na.drop(2).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-----+-----+\n",
      "|  Id| Name|Sales|\n",
      "+----+-----+-----+\n",
      "|emp1| John|100.0|\n",
      "|emp2| null|100.0|\n",
      "|emp3| null|345.0|\n",
      "|emp4|Cindy|456.0|\n",
      "+----+-----+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.na.fill(100).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-------+-----+\n",
      "|  Id|   Name|Sales|\n",
      "+----+-------+-----+\n",
      "|emp1|   John| null|\n",
      "|emp2|Missing| null|\n",
      "|emp3|Missing|345.0|\n",
      "|emp4|  Cindy|456.0|\n",
      "+----+-------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.na.fill(\"Missing\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-------+-----+\n",
      "|  Id|   Name|Sales|\n",
      "+----+-------+-----+\n",
      "|emp1|   John| null|\n",
      "|emp2|Missing| null|\n",
      "|emp3|Missing|345.0|\n",
      "|emp4|  Cindy|456.0|\n",
      "+----+-------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.na.fill(\"Missing\", Array(\"Name\")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+----+-----+-----------------+\n",
      "|summary|  Id| Name|            Sales|\n",
      "+-------+----+-----+-----------------+\n",
      "|  count|   4|    2|                2|\n",
      "|   mean|null| null|            400.5|\n",
      "| stddev|null| null|78.48885271170677|\n",
      "|    min|emp1|Cindy|            345.0|\n",
      "|    max|emp4| John|            456.0|\n",
      "+-------+----+-----+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.describe().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-----+-----+\n",
      "|  Id| Name|Sales|\n",
      "+----+-----+-----+\n",
      "|emp1| John|400.5|\n",
      "|emp2| null|400.5|\n",
      "|emp3| null|345.0|\n",
      "|emp4|Cindy|456.0|\n",
      "+----+-----+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.na.fill(400.5, Array(\"Sales\")).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Date and timestamp**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "import org.apache.spark.sql.SparkSession\r\n",
       "spark: org.apache.spark.sql.SparkSession = org.apache.spark.sql.SparkSession@2a7dc01c\r\n"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import org.apache.spark.sql.SparkSession\n",
    "val spark = SparkSession.builder().getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----+-----+-----+-----+-------+\n",
      "|      Date| Open| High|  Low|Close| Volume|\n",
      "+----------+-----+-----+-----+-----+-------+\n",
      "|2006-01-03|490.0|493.8|481.1|492.9|1537660|\n",
      "|2006-01-04|488.6|491.0|483.5|483.8|1871020|\n",
      "|2006-01-05|484.4|487.8|484.0|486.2|1143160|\n",
      "|2006-01-06|488.8|489.0|482.0|486.2|1370250|\n",
      "|2006-01-09|486.0|487.4|483.0|483.9|1680740|\n",
      "|2006-01-10|483.0|485.5|480.8|485.4|1365960|\n",
      "|2006-01-11|495.8|495.8|485.8|489.8|1684440|\n",
      "|2006-01-12|491.0|491.0|488.8|490.3|1230060|\n",
      "|2006-01-13|491.0|491.9|487.3|489.2| 940930|\n",
      "|2006-01-17|485.1|487.0|482.7|484.3|1237830|\n",
      "|2006-01-18|484.3|486.7|481.1|483.8|1218910|\n",
      "|2006-01-19|485.6|485.8|477.0|479.4|1696500|\n",
      "|2006-01-20|472.1|474.0|456.3|456.9|4781930|\n",
      "|2006-01-23|460.0|463.8|457.0|460.0|2025500|\n",
      "|2006-01-24|462.9|463.6|459.9|460.1|2083740|\n",
      "|2006-01-25|461.4|463.7|460.1|462.3|1591940|\n",
      "|2006-01-26|465.5|475.5|464.5|470.1|1988600|\n",
      "|2006-01-27|470.1|473.7|466.0|468.7|1412760|\n",
      "|2006-01-30|468.7|469.9|466.6|468.2|1057630|\n",
      "|2006-01-31|468.3|470.5|465.5|465.8|1887280|\n",
      "+----------+-----+-----+-----+-----+-------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "df: org.apache.spark.sql.DataFrame = [Date: string, Open: double ... 4 more fields]\r\n"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val df = spark.read.option(\"header\", \"true\").option(\"inferSchema\", \"true\").csv(\"./datasets/CitiGroup2006_2008\")\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Date: string (nullable = true)\n",
      " |-- Open: double (nullable = true)\n",
      " |-- High: double (nullable = true)\n",
      " |-- Low: double (nullable = true)\n",
      " |-- Close: double (nullable = true)\n",
      " |-- Volume: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+\n",
      "|month(Date)|\n",
      "+-----------+\n",
      "|          1|\n",
      "|          1|\n",
      "|          1|\n",
      "|          1|\n",
      "|          1|\n",
      "|          1|\n",
      "|          1|\n",
      "|          1|\n",
      "|          1|\n",
      "|          1|\n",
      "|          1|\n",
      "|          1|\n",
      "|          1|\n",
      "|          1|\n",
      "|          1|\n",
      "|          1|\n",
      "|          1|\n",
      "|          1|\n",
      "|          1|\n",
      "|          1|\n",
      "+-----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(month(df(\"Date\"))).show() // year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+------------------+\n",
      "|Year|        avg(Close)|\n",
      "+----+------------------+\n",
      "|2007| 477.8203984063745|\n",
      "|2006| 489.2697211155379|\n",
      "|2008|190.48893280632404|\n",
      "+----+------------------+\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "df2: org.apache.spark.sql.DataFrame = [Date: string, Open: double ... 5 more fields]\r\n",
       "dfavgs: org.apache.spark.sql.DataFrame = [Year: int, avg(Open): double ... 5 more fields]\r\n"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val df2 = df.withColumn(\"Year\", year(df(\"Date\")))\n",
    "val dfavgs = df2. groupBy(\"Year\").mean()\n",
    "\n",
    "dfavgs.select($\"Year\", $\"avg(Close)\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+----------+\n",
      "|Year|max(Close)|\n",
      "+----+----------+\n",
      "|2007|     552.5|\n",
      "|2006|     564.1|\n",
      "|2008|     296.9|\n",
      "+----+----------+\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "df2: org.apache.spark.sql.DataFrame = [Date: string, Open: double ... 5 more fields]\r\n",
       "df3: org.apache.spark.sql.DataFrame = [Year: int, max(Open): double ... 5 more fields]\r\n"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val df2 = df.withColumn(\"Year\", year(df(\"Date\")))\n",
    "val df3 = df2. groupBy(\"Year\").max()\n",
    "\n",
    "df3.select($\"Year\", $\"max(Close)\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "spylon-kernel",
   "language": "scala",
   "name": "spylon-kernel"
  },
  "language_info": {
   "codemirror_mode": "text/x-scala",
   "file_extension": ".scala",
   "help_links": [
    {
     "text": "MetaKernel Magics",
     "url": "https://metakernel.readthedocs.io/en/latest/source/README.html"
    }
   ],
   "mimetype": "text/x-scala",
   "name": "scala",
   "pygments_lexer": "scala",
   "version": "0.4.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

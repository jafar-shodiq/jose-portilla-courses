{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "import org.apache.spark.sql.SparkSession\r\n",
       "import org.apache.spark.ml.feature.{VectorAssembler, StringIndexer, VectorIndexer, OneHotEncoder}\r\n",
       "import org.apache.spark.ml.classification.LogisticRegression\r\n",
       "import org.apache.spark.ml.linalg.Vectors\r\n",
       "import org.apache.spark.ml.Pipeline\r\n",
       "import org.apache.spark.mllib.evaluation.MulticlassMetrics\r\n"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import org.apache.spark.sql.SparkSession\n",
    "import org.apache.spark.ml.feature.{VectorAssembler, StringIndexer, VectorIndexer, OneHotEncoder}\n",
    "import org.apache.spark.ml.classification.LogisticRegression\n",
    "import org.apache.spark.ml.linalg.Vectors\n",
    "import org.apache.spark.ml.Pipeline\n",
    "import org.apache.spark.mllib.evaluation.MulticlassMetrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------------+---+-----------+--------------------+--------------------+-----------------+----+--------------------+-------------------+-------------+\n",
      "|Daily Time Spent on Site|Age|Area Income|Daily Internet Usage|       Ad Topic Line|             City|Male|             Country|          Timestamp|Clicked on Ad|\n",
      "+------------------------+---+-----------+--------------------+--------------------+-----------------+----+--------------------+-------------------+-------------+\n",
      "|                   68.95| 35|    61833.9|              256.09|Cloned 5thgenerat...|      Wrightburgh|   0|             Tunisia|2016-03-27 00:53:11|            0|\n",
      "|                   80.23| 31|   68441.85|              193.77|Monitored nationa...|        West Jodi|   1|               Nauru|2016-04-04 01:39:02|            0|\n",
      "|                   69.47| 26|   59785.94|               236.5|Organic bottom-li...|         Davidton|   0|          San Marino|2016-03-13 20:35:42|            0|\n",
      "|                   74.15| 29|   54806.18|              245.89|Triple-buffered r...|   West Terrifurt|   1|               Italy|2016-01-10 02:31:19|            0|\n",
      "|                   68.37| 35|   73889.99|              225.58|Robust logistical...|     South Manuel|   0|             Iceland|2016-06-03 03:36:18|            0|\n",
      "|                   59.99| 23|   59761.56|              226.74|Sharable client-d...|        Jamieberg|   1|              Norway|2016-05-19 14:30:17|            0|\n",
      "|                   88.91| 33|   53852.85|              208.36|Enhanced dedicate...|      Brandonstad|   0|             Myanmar|2016-01-28 20:59:32|            0|\n",
      "|                    66.0| 48|   24593.33|              131.76|Reactive local ch...| Port Jefferybury|   1|           Australia|2016-03-07 01:40:15|            1|\n",
      "|                   74.53| 30|    68862.0|              221.51|Configurable cohe...|       West Colin|   1|             Grenada|2016-04-18 09:33:42|            0|\n",
      "|                   69.88| 20|   55642.32|              183.82|Mandatory homogen...|       Ramirezton|   1|               Ghana|2016-07-11 01:42:51|            0|\n",
      "|                   47.64| 49|   45632.51|              122.02|Centralized neutr...|  West Brandonton|   0|               Qatar|2016-03-16 20:19:01|            1|\n",
      "|                   83.07| 37|   62491.01|              230.87|Team-oriented gri...|East Theresashire|   1|             Burundi|2016-05-08 08:10:10|            0|\n",
      "|                   69.57| 48|   51636.92|              113.12|Centralized conte...|   West Katiefurt|   1|               Egypt|2016-06-03 01:14:41|            1|\n",
      "|                   79.52| 24|   51739.63|              214.23|Synergistic fresh...|       North Tara|   0|Bosnia and Herzeg...|2016-04-20 21:49:22|            0|\n",
      "|                   42.95| 33|    30976.0|              143.56|Grass-roots coher...|     West William|   0|            Barbados|2016-03-24 09:31:49|            1|\n",
      "|                   63.45| 23|   52182.23|              140.64|Persistent demand...|   New Travistown|   1|               Spain|2016-03-09 03:41:30|            1|\n",
      "|                   55.39| 37|   23936.86|              129.41|Customizable mult...|   West Dylanberg|   0|Palestinian Terri...|2016-01-30 19:20:41|            1|\n",
      "|                   82.03| 41|   71511.08|              187.53|Intuitive dynamic...|      Pruittmouth|   0|         Afghanistan|2016-05-02 07:00:58|            0|\n",
      "|                    54.7| 36|   31087.54|              118.39|Grass-roots solut...|      Jessicastad|   1|British Indian Oc...|2016-02-13 07:53:55|            1|\n",
      "|                   74.58| 40|   23821.72|              135.51|Advanced 24/7 pro...|       Millertown|   1|  Russian Federation|2016-02-27 04:43:07|            1|\n",
      "+------------------------+---+-----------+--------------------+--------------------+-----------------+----+--------------------+-------------------+-------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "spark: org.apache.spark.sql.SparkSession = org.apache.spark.sql.SparkSession@a4b53c4\r\n",
       "data: org.apache.spark.sql.DataFrame = [Daily Time Spent on Site: double, Age: int ... 8 more fields]\r\n"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val spark = SparkSession.builder().getOrCreate()\n",
    "val data = spark.read.option(\"header\", \"true\")\n",
    "            .option(\"inferSchema\", \"true\")\n",
    "            .format(\"csv\")\n",
    "            .load(\"../datasets/advertising.csv\")\n",
    "data.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Daily Time Spent on Site: double (nullable = true)\n",
      " |-- Age: integer (nullable = true)\n",
      " |-- Area Income: double (nullable = true)\n",
      " |-- Daily Internet Usage: double (nullable = true)\n",
      " |-- Ad Topic Line: string (nullable = true)\n",
      " |-- City: string (nullable = true)\n",
      " |-- Male: integer (nullable = true)\n",
      " |-- Country: string (nullable = true)\n",
      " |-- Timestamp: string (nullable = true)\n",
      " |-- Clicked on Ad: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "res3: Array[org.apache.spark.sql.Row] = Array([68.95,35,61833.9,256.09,Cloned 5thgeneration orchestration,Wrightburgh,0,Tunisia,2016-03-27 00:53:11,0])\r\n"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example Data Row\n",
      "Age\n",
      "35\n",
      "\n",
      "\n",
      "Area Income\n",
      "61833.9\n",
      "\n",
      "\n",
      "Daily Internet Usage\n",
      "256.09\n",
      "\n",
      "\n",
      "Ad Topic Line\n",
      "Cloned 5thgeneration orchestration\n",
      "\n",
      "\n",
      "City\n",
      "Wrightburgh\n",
      "\n",
      "\n",
      "Male\n",
      "0\n",
      "\n",
      "\n",
      "Country\n",
      "Tunisia\n",
      "\n",
      "\n",
      "Timestamp\n",
      "2016-03-27 00:53:11\n",
      "\n",
      "\n",
      "Clicked on Ad\n",
      "0\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "colnames: Array[String] = Array(Daily Time Spent on Site, Age, Area Income, Daily Internet Usage, Ad Topic Line, City, Male, Country, Timestamp, Clicked on Ad)\r\n",
       "firstrow: org.apache.spark.sql.Row = [68.95,35,61833.9,256.09,Cloned 5thgeneration orchestration,Wrightburgh,0,Tunisia,2016-03-27 00:53:11,0]\r\n"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val colnames = data.columns\n",
    "val firstrow = data.head(1)(0)\n",
    "println(\"Example Data Row\")\n",
    "for(ind <- Range(1,colnames.length)){\n",
    "  println(colnames(ind))\n",
    "  println(firstrow(ind))\n",
    "  println(\"\\n\")\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "timedata: org.apache.spark.sql.DataFrame = [Daily Time Spent on Site: double, Age: int ... 9 more fields]\r\n"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val timedata = data.withColumn(\"Hour\", hour(data(\"Timestamp\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "df: org.apache.spark.sql.DataFrame = [label: int, Daily Time Spent on Site: double ... 5 more fields]\r\n"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val df = timedata.select(data(\"Clicked on Ad\").as(\"label\"),\n",
    "                         $\"Daily Time Spent on Site\", $\"Age\", $\"Area Income\", $\"Daily Internet Usage\", $\"Hour\", $\"Male\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "assembler: org.apache.spark.ml.feature.VectorAssembler = VectorAssembler: uid=vecAssembler_c9fe68448861, handleInvalid=error, numInputCols=6\r\n"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val assembler = new VectorAssembler()\n",
    "                .setInputCols(Array(\"Daily Time Spent on Site\", \"Age\", \"Area Income\", \"Daily Internet Usage\", \"Hour\", \"Male\"))\n",
    "                .setOutputCol(\"features\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "train: org.apache.spark.sql.Dataset[org.apache.spark.sql.Row] = [label: int, Daily Time Spent on Site: double ... 5 more fields]\r\n",
       "test: org.apache.spark.sql.Dataset[org.apache.spark.sql.Row] = [label: int, Daily Time Spent on Site: double ... 5 more fields]\r\n"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val Array(train, test) = df.randomSplit(Array(0.7, 0.3), seed=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "lr: org.apache.spark.ml.classification.LogisticRegression = logreg_ad31a6aa16d2\r\n"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val lr = new LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pipeline: org.apache.spark.ml.Pipeline = pipeline_dc4a8fe3fcad\r\n"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val pipeline = new Pipeline()\n",
    "                .setStages(Array(assembler, lr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "model: org.apache.spark.ml.PipelineModel = pipeline_dc4a8fe3fcad\r\n"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val model = pipeline.fit(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "results: org.apache.spark.sql.DataFrame = [label: int, Daily Time Spent on Site: double ... 9 more fields]\r\n"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val results = model.transform(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "predictionAndLabels: org.apache.spark.rdd.RDD[(Double, Double)] = MapPartitionsRDD[103] at rdd at <console>:33\r\n"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val predictionAndLabels = results.select($\"prediction\", $\"label\")\n",
    "                            .as[(Double, Double)].rdd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "metrics: org.apache.spark.mllib.evaluation.MulticlassMetrics = org.apache.spark.mllib.evaluation.MulticlassMetrics@35e298a8\r\n"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val metrics = new MulticlassMetrics(predictionAndLabels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "res17: org.apache.spark.mllib.linalg.Matrix =\r\n",
       "125.0  1.0\r\n",
       "6.0    124.0\r\n"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.confusionMatrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "spylon-kernel",
   "language": "scala",
   "name": "spylon-kernel"
  },
  "language_info": {
   "codemirror_mode": "text/x-scala",
   "file_extension": ".scala",
   "help_links": [
    {
     "text": "MetaKernel Magics",
     "url": "https://metakernel.readthedocs.io/en/latest/source/README.html"
    }
   ],
   "mimetype": "text/x-scala",
   "name": "scala",
   "pygments_lexer": "scala",
   "version": "0.4.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

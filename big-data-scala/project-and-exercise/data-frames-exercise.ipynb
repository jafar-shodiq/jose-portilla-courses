{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "import org.apache.spark.sql.SparkSession\r\n",
       "spark: org.apache.spark.sql.SparkSession = org.apache.spark.sql.SparkSession@2e452be\r\n"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import org.apache.spark.sql.SparkSession\n",
    "val spark = SparkSession.builder().getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----------------+------------------+----------+-----------------+---------+------------------+\n",
      "|      Date|             Open|              High|       Low|            Close|   Volume|         Adj Close|\n",
      "+----------+-----------------+------------------+----------+-----------------+---------+------------------+\n",
      "|2011-10-24|       119.100002|120.28000300000001|115.100004|       118.839996|120460200|         16.977142|\n",
      "|2011-10-25|        74.899999|         79.390001| 74.249997|        77.370002|315541800|11.052857000000001|\n",
      "|2011-10-26|            78.73|         81.420001| 75.399997|        79.400002|148733900|         11.342857|\n",
      "|2011-10-27|        82.179998| 82.71999699999999| 79.249998|80.86000200000001| 71190000|11.551428999999999|\n",
      "|2011-10-28|        80.280002|         84.660002| 79.599999|84.14000300000001| 57769600|             12.02|\n",
      "|2011-10-31|83.63999799999999|         84.090002| 81.450002|        82.080003| 39653600|         11.725715|\n",
      "|2011-11-01|        80.109998|         80.999998|     78.74|        80.089997| 33016200|         11.441428|\n",
      "|2011-11-02|        80.709998|         84.400002| 80.109998|        83.389999| 41384000|         11.912857|\n",
      "|2011-11-03|        84.130003|         92.600003| 81.800003|        92.290003| 94685500|13.184285999999998|\n",
      "|2011-11-04|91.46999699999999| 92.89000300000001| 87.749999|        90.019998| 84483700|             12.86|\n",
      "|2011-11-07|             91.0|         93.839998| 89.979997|        90.830003| 47485200|         12.975715|\n",
      "|2011-11-08|91.22999899999999|         92.600003| 89.650002|        90.470001| 31906000|         12.924286|\n",
      "|2011-11-09|        89.000001|         90.440001| 87.999998|        88.049999| 28756000|         12.578571|\n",
      "|2011-11-10|        89.290001| 90.29999699999999| 84.839999|85.11999899999999| 39614400|             12.16|\n",
      "|2011-11-11|        85.899997|         87.949997|      83.7|        87.749999| 38140200|         12.535714|\n",
      "|2011-11-14|        87.989998|              88.1|     85.45|        85.719999| 21811300|         12.245714|\n",
      "|2011-11-15|            85.15|         87.050003| 84.499998|        86.279999| 21372400|         12.325714|\n",
      "|2011-11-16|        86.460003|         86.460003| 80.890002|        81.180002| 34560400|11.597142999999999|\n",
      "|2011-11-17|            80.77|         80.999998| 75.789999|        76.460001| 52823400|         10.922857|\n",
      "|2011-11-18|             76.7|         78.999999| 76.039998|        78.059998| 34729100|         11.151428|\n",
      "+----------+-----------------+------------------+----------+-----------------+---------+------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "df: org.apache.spark.sql.DataFrame = [Date: string, Open: double ... 5 more fields]\r\n"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val df = spark.read.option(\"header\", \"true\").option(\"inferSchema\", \"true\").csv(\"../datasets/Netflix_2011_2016.csv\")\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Date: string (nullable = true)\n",
      " |-- Open: double (nullable = true)\n",
      " |-- High: double (nullable = true)\n",
      " |-- Low: double (nullable = true)\n",
      " |-- Close: double (nullable = true)\n",
      " |-- Volume: integer (nullable = true)\n",
      " |-- Adj Close: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+----------+------------------+------------------+------------------+------------------+--------------------+------------------+\n",
      "|summary|      Date|              Open|              High|               Low|             Close|              Volume|         Adj Close|\n",
      "+-------+----------+------------------+------------------+------------------+------------------+--------------------+------------------+\n",
      "|  count|      1259|              1259|              1259|              1259|              1259|                1259|              1259|\n",
      "|   mean|      null|230.39351086656092|233.97320872915006|226.80127876251044|  230.522453845909|2.5634836060365368E7|55.610540036536875|\n",
      "| stddev|      null|164.37456353264244| 165.9705082667129| 162.6506358235739|164.40918905512854| 2.306312683388607E7|35.186669331525486|\n",
      "|    min|2011-10-24|         53.990001|         55.480001|             52.81|              53.8|             3531300|          7.685714|\n",
      "|    max|2016-10-24|        708.900017|        716.159996|        697.569984|        707.610001|           315541800|        130.929993|\n",
      "+-------+----------+------------------+------------------+------------------+------------------+--------------------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.describe().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "res4: Array[String] = Array(Date, Open, High, Low, Close, Volume, Adj Close)\r\n"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "res5: Array[org.apache.spark.sql.Row] = Array([2011-10-24,119.100002,120.28000300000001,115.100004,118.839996,120460200,16.977142], [2011-10-25,74.899999,79.390001,74.249997,77.370002,315541800,11.052857000000001], [2011-10-26,78.73,81.420001,75.399997,79.400002,148733900,11.342857], [2011-10-27,82.179998,82.71999699999999,79.249998,80.86000200000001,71190000,11.551428999999999], [2011-10-28,80.280002,84.660002,79.599999,84.14000300000001,57769600,12.02])\r\n"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "df2: org.apache.spark.sql.DataFrame = [Date: string, Open: double ... 6 more fields]\r\n"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val df2 = df.withColumn(\"HV Ratio\", df(\"High\") / df(\"Volume\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+------------------+---------+-----+---------+--------+---------+\n",
      "|      Date|              Open|     High|  Low|    Close|  Volume|Adj Close|\n",
      "+----------+------------------+---------+-----+---------+--------+---------+\n",
      "|2012-08-03|54.860001000000004|55.480001|52.81|53.909999|37295300| 7.701428|\n",
      "+----------+------------------+---------+-----+---------+--------+---------+\n",
      "only showing top 1 row\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.orderBy(\"High\").show(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+\n",
      "|      avg(Close)|\n",
      "+----------------+\n",
      "|230.522453845909|\n",
      "+----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(mean(\"Close\")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-----------+\n",
      "|max(Volume)|min(Volume)|\n",
      "+-----------+-----------+\n",
      "|  315541800|    3531300|\n",
      "+-----------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(max(\"Volume\"), min(\"Volume\")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "import spark.implicits._\r\n"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import spark.implicits._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "res15: Long = 1218\r\n"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.filter($\"Close\" < 600).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "res19: Double = 0.04924543288324067\r\n"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.filter($\"High\" > 500).count()*1.0 / df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|  corr(High, Volume)|\n",
      "+--------------------+\n",
      "|-0.20960233287942157|\n",
      "+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(corr(\"High\", \"Volume\")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+------------------+\n",
      "|Year|         max(High)|\n",
      "+----+------------------+\n",
      "|2015|        716.159996|\n",
      "|2013|        389.159988|\n",
      "|2014|        489.290024|\n",
      "|2012|        133.429996|\n",
      "|2016|129.28999299999998|\n",
      "|2011|120.28000300000001|\n",
      "+----+------------------+\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "df2: org.apache.spark.sql.DataFrame = [Date: string, Open: double ... 6 more fields]\r\n",
       "df3: org.apache.spark.sql.DataFrame = [Year: int, max(Open): double ... 6 more fields]\r\n"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val df2 = df.withColumn(\"Year\", year(df(\"Date\")))\n",
    "val df3 = df2. groupBy(\"Year\").max()\n",
    "\n",
    "df3.select($\"Year\", $\"max(High)\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+------------------+\n",
      "|Month|        avg(Close)|\n",
      "+-----+------------------+\n",
      "|    1|212.22613874257422|\n",
      "|    2| 254.1954634020619|\n",
      "|    3| 249.5825228971963|\n",
      "|    4|246.97514271428562|\n",
      "|    5|264.37037614150944|\n",
      "|    6| 295.1597153490566|\n",
      "|    7|243.64747528037387|\n",
      "|    8|195.25599892727263|\n",
      "|    9|206.09598121568627|\n",
      "|   10|205.93297300900903|\n",
      "|   11| 194.3172275445545|\n",
      "|   12| 199.3700942358491|\n",
      "+-----+------------------+\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "df2: org.apache.spark.sql.DataFrame = [Date: string, Open: double ... 6 more fields]\r\n",
       "df3: org.apache.spark.sql.DataFrame = [Month: int, avg(Open): double ... 6 more fields]\r\n"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val df2 = df.withColumn(\"Month\", month(df(\"Date\")))\n",
    "val df3 = df2. groupBy(\"Month\").mean()\n",
    "\n",
    "df3.select($\"Month\", $\"avg(Close)\").orderBy(\"Month\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "spylon-kernel",
   "language": "scala",
   "name": "spylon-kernel"
  },
  "language_info": {
   "codemirror_mode": "text/x-scala",
   "file_extension": ".scala",
   "help_links": [
    {
     "text": "MetaKernel Magics",
     "url": "https://metakernel.readthedocs.io/en/latest/source/README.html"
    }
   ],
   "mimetype": "text/x-scala",
   "name": "scala",
   "pygments_lexer": "scala",
   "version": "0.4.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
